{"cells":[{"metadata":{"_uuid":"baba78b6-7b88-478a-ba04-e4a93d7357ee","_cell_guid":"6593597d-293c-4a99-827e-53dfcc3c1a01","trusted":true},"cell_type":"code","source":"# %% [code] {\"id\":\"QpH0zvdTHUV9\",\"colab_type\":\"code\",\"colab\":{}}\nimport cv2\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plot\n%matplotlib inline\n\n# %% [markdown]\n# **Import tensorflow libraries**\n\n# %% [code] {\"id\":\"pxfvGsH4bIzH\",\"colab_type\":\"code\",\"outputId\":\"2d8b2f59-f958-449a-ab14-734bfc6b11bc\",\"colab\":{\"base_uri\":\"https://localhost:8080/\",\"height\":34}}\nimport tensorflow\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# %% [code] {\"id\":\"QdXsXtTkbM5k\",\"colab_type\":\"code\",\"outputId\":\"d7821814-d827-42f8-c240-1eae6a2a815e\",\"colab\":{\"base_uri\":\"https://localhost:8080/\",\"height\":34}}\nimport os\nos.listdir(\"../input/\")\n\n# %% [markdown]\n# **The below function fetches all the images of training set from the directory.**\n\n# %% [code] {\"id\":\"MHc4zpczBZNA\",\"colab_type\":\"code\",\"colab\":{}}\ndef get_images(directory):\n    Images = []\n    Labels = []\n    for dir_name in os.listdir(directory): \n        for image_file in os.listdir(directory+dir_name):\n            image = cv2.imread(directory+dir_name+r'/'+image_file)\n            if image is not None:\n                image = cv2.resize(image,(300,300),)\n                Images.append(image)\n                Labels.append(dir_name)\n    return Images, Labels\n\n# %% [code] {\"id\":\"7FWuFWqxBeYY\",\"colab_type\":\"code\",\"colab\":{}}\nImages, Labels = get_images('../input/train/')\n\n# %% [markdown]\n# **Encoding the text labels to numericals, since machine learning models only understand data in numbers.**\n\n# %% [code] {\"id\":\"xu0ihZnTHY5S\",\"colab_type\":\"code\",\"colab\":{}}\nlabels = []\nmapping = { 'Sugar beet': 0, 'Fat Hen': 1, 'Scentless Mayweed' : 2, 'Charlock' : 3,\n           'Small-flowered Cranesbill': 4, 'Maize': 5, 'Shepherds Purse' :6, 'Common wheat': 7,\n           'Common Chickweed': 8, 'Cleavers': 9, 'Loose Silky-bent' : 10, 'Black-grass': 11 }\nfor label in Labels:\n    labels.append(mapping[label])\ndel Labels\n\n# %% [code] {\"id\":\"MGm0yoZK_h-p\",\"colab_type\":\"code\",\"colab\":{\"base_uri\":\"https://localhost:8080/\",\"height\":34},\"outputId\":\"05be089f-fd3e-4ed5-88d9-963b20dad870\"}\nImages[0].shape\n\n# %% [markdown]\n# **Reshaping the images to 4 dimensional tensors. (Model requires the input data to be in 4 dimensional format [no. of images, height, width, channels])**\n\n# %% [code] {\"id\":\"S5BkEVq0CXCJ\",\"colab_type\":\"code\",\"colab\":{}}\nImages = np.reshape(Images,(-1,300,300,3))\nLabels = np.array(labels)\n\n# %% [code] {\"id\":\"TvDIL2DfD8Lv\",\"colab_type\":\"code\",\"outputId\":\"cd2dde8f-b614-49fb-b6f9-117d196874b3\",\"colab\":{\"base_uri\":\"https://localhost:8080/\",\"height\":50}}\nprint(\"Shape of training data: \", Images.shape)\nprint(\"Shape of labels data: \", Labels.shape)\n\n# %% [markdown]\n# **Splitting the data into Training and Validation to check the accuracy of the model on unseen data. **\n\n# %% [code] {\"id\":\"4hrCXjapPFB1\",\"colab_type\":\"code\",\"colab\":{}}\nfrom sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(Images, Labels, test_size=.2, random_state=42, stratify = Labels)\n\n# %% [markdown]\n# **The below function performs one hot encoding on the labels.**\n\n# %% [code] {\"id\":\"j53KKooFZuCu\",\"colab_type\":\"code\",\"colab\":{}}\nfrom keras.utils import np_utils\ny_train = np_utils.to_categorical(y_train,num_classes=12)\ny_val = np_utils.to_categorical(y_val,num_classes=12)\n\n# %% [markdown]\n# **ImageDataGenerator helps in image augmentation by performing various operations on the existing images.**\n\n# %% [code] {\"id\":\"jYjs8GDIMzJf\",\"colab_type\":\"code\",\"colab\":{}}\ntrain_datagen = ImageDataGenerator(\n                                   rotation_range=20,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                  )\n\nvalidation_datagen = ImageDataGenerator()\n\n# %% [code]\ndel Images\ndel Labels\n\n# %% [code] {\"id\":\"dt98WrdSNkaw\",\"colab_type\":\"code\",\"colab\":{}}\ntrain_generator = train_datagen.flow(x_train, y_train, batch_size=32)\nvalidation_generator = validation_datagen.flow(x_val, y_val, batch_size=16)\n\n# %% [markdown]\n# **Here, I am using VGG16 Pretrained Network**\n\n# %% [code] {\"id\":\"cOIyxa4ezEOk\",\"colab_type\":\"code\",\"outputId\":\"9750363f-e81e-42d8-97a0-1744be220231\",\"colab\":{\"base_uri\":\"https://localhost:8080/\",\"height\":121}}\nfrom tensorflow.keras.applications import VGG16\nvgg = VGG16(include_top=\n            False, weights='imagenet', input_shape = (300,300,3))\n\n# %% [code] {\"id\":\"2WXE5t84w1nH\",\"colab_type\":\"code\",\"colab\":{}}\nimport tensorflow.keras.optimizers as Optimizer\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout, GlobalAvgPool2D, GlobalMaxPooling2D, Concatenate\nfrom tensorflow.keras.models import Model\n\n# %% [code] {\"id\":\"xoxZQQdlzETk\",\"colab_type\":\"code\",\"colab\":{}}\nvgg.trainable=False\nfor layer in vgg.layers:\n    layer.trainable = False\n\nfc1 = Concatenate(axis=-1)([GlobalAvgPool2D()(vgg.output), GlobalMaxPooling2D()(vgg.output)])\nfc1 = Dense(400, activation='relu')(fc1)\nfc1_dropout = Dropout(0.3)(fc1)\nfc2 = Dense(200, activation='relu')(fc1_dropout)\nfc2_dropout = Dropout(0.3)(fc2)\nfc2 = Dense(75, activation='relu')(fc1_dropout)\noutput = Dense(12, activation='softmax')(fc2_dropout)\nmodel = Model(vgg.input, output)\n\nmodel.compile(optimizer=Optimizer.Adam(lr=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.summary()\n\n\n# %% [markdown]\n# **During training, you can save the model's best weights using ModelCheckpoint. The one with the minimum validation loss is saved.**\n\n# %% [code] {\"id\":\"9R_KViGUV-CQ\",\"colab_type\":\"code\",\"outputId\":\"3ca75b77-daa4-4171-fafc-bfb626460232\",\"colab\":{\"base_uri\":\"https://localhost:8080/\",\"height\":6938}}\nfrom tensorflow.keras.callbacks import ModelCheckpoint\ncheckpoint = ModelCheckpoint('saved_model.hdf5', monitor='val_loss', verbose=1, save_weights_only=True, save_best_only=True, mode='min')\ncallbacks_list = [checkpoint]\ntrained = model.fit_generator(train_generator,steps_per_epoch = 25, epochs=200, validation_data = validation_generator,\n                              validation_steps=10, \n                              verbose=1, callbacks = callbacks_list)\n\n# %% [markdown]\n# **Plotting the graph of model's accuracy and loss.**\n\n# %% [code] {\"id\":\"X02kvmYeLb1T\",\"colab_type\":\"code\",\"colab\":{\"base_uri\":\"https://localhost:8080/\",\"height\":574},\"outputId\":\"9898bdaf-1b9d-49a7-f12a-33179d260244\"}\nplot.plot(trained.history['acc'])\nplot.plot(trained.history['val_acc'])\nplot.title('Model accuracy')\nplot.ylabel('Accuracy')\nplot.xlabel('Epoch')\nplot.legend(['Train', 'Test'], loc='upper left')\nplot.show()\n\nplot.plot(trained.history['loss'])\nplot.plot(trained.history['val_loss'])\nplot.title('Model loss')\nplot.ylabel('Loss')\nplot.xlabel('Epoch')\nplot.legend(['Train', 'Test'], loc='upper left')\nplot.show()\n\n# %% [code] {\"id\":\"_yA0Cgu2Wx-s\",\"colab_type\":\"code\",\"colab\":{}}\ndef get_test_images(directory):\n    Images = []\n    Image_names = []\n    for image_file in os.listdir(directory):\n        Image_names.append(image_file)\n        image = cv2.imread(directory+r'/'+image_file)\n        if image is not None:\n            image = cv2.resize(image,(300,300),)\n            Images.append(image)\n    return Images, Image_names\n\n# %% [code] {\"id\":\"RFK7jETxNcKL\",\"colab_type\":\"code\",\"colab\":{}}\ntest_images, image_names = get_test_images('../input/test/')\ntest_images = np.array(test_images)\nprint(test_images.shape)\n\n# %% [markdown]\n# **Here, To load the saved weights we need to define the same model architecture again. Also, make sure you do not compile the model this time.**\n\n# %% [code]\nvgg = VGG16(include_top=\n            False, weights='imagenet', input_shape = (300,300,3))\n\nvgg.trainable=False\nfor layer in vgg.layers:\n    layer.trainable = False\n\nfc1 = Concatenate(axis=-1)([GlobalAvgPool2D()(vgg.output), GlobalMaxPooling2D()(vgg.output)])\nfc1 = Dense(400, activation='relu')(fc1)\nfc1_dropout = Dropout(0.3)(fc1)\nfc2 = Dense(200, activation='relu')(fc1_dropout)\nfc2_dropout = Dropout(0.3)(fc2)\nfc2 = Dense(75, activation='relu')(fc1_dropout)\noutput = Dense(12, activation='softmax')(fc2_dropout)\nmodel = Model(vgg.input, output)\n\n# %% [code]\nmodel.load_weights('saved_model.hdf5')\n\n# %% [markdown]\n# **If you ever want to save the entire model, you can save using tensorflow.keras.models.save_model()**\n\n# %% [code]\ntensorflow.keras.models.save_model(\n    model,\n    'tf_model.hdf5',\n    overwrite=True,\n    include_optimizer=True\n)\n\n# %% [markdown]\n# **Then you can load the entire model using from tensorflow.keras.models**\n\n# %% [code]\nfrom tensorflow.keras.models import load_model\nmodel = load_model('tf_model.hdf5')\n\n# %% [markdown]\n# **Here, the model predicts the new images using function model.predict()**\n\n# %% [code] {\"id\":\"vUzsKdL7QrtI\",\"colab_type\":\"code\",\"colab\":{}}\npredictions = model.predict(test_images)\npredictions = np.argmax(predictions, axis = 1)\n\n# %% [code]\nlabelled_predictions = []\nmapping = {0: 'Sugar beet',1:'Fat Hen' ,2: 'Scentless Mayweed',3:  'Charlock', \n        4:'Small-flowered Cranesbill', 5:'Maize' ,\n        6: 'Shepherds Purse' ,7:'Common wheat' ,8:'Common Chickweed' ,\n        9:'Cleavers' ,10:'Loose Silky-bent'  ,11: 'Black-grass'}\nfor pred in predictions:\n    labelled_predictions.append(mapping[pred])\n\n# %% [markdown]\n# **Preparing the predictions for submission**\n\n# %% [code] {\"id\":\"zQ_hh0ZuPB2_\",\"colab_type\":\"code\",\"colab\":{\"base_uri\":\"https://localhost:8080/\",\"height\":806},\"outputId\":\"b2c5edbf-4d6e-43f7-e977-ce3a631694b2\"}\nd = []\ni=0\nfor pred in labelled_predictions:\n    d.append({'file': image_names[i], 'species': pred})\n    i=i+1\noutput = pd.DataFrame(d)\noutput.to_csv('submission.csv',index=False)","execution_count":0,"outputs":[]}],"metadata":{"colab":{"name":"Plant Seedling Classification","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":1}